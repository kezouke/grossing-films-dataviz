{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:07:24.502627Z",
     "start_time": "2025-02-28T22:07:24.487254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import sqlite3\n",
    "import time\n",
    "\n",
    "WIKI_URL = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n",
    "\n",
    "# We'll look for these table captions.\n",
    "MAIN_TABLE_CAPTIONS = [\n",
    "    \"Highest-grossing films\",  # The primary table listing top films\n",
    "    # Optionally include other tables from the page if needed:\n",
    "    #\"Highest-grossing films as of 2023 adjusted for inflation\",\n",
    "    #\"High-grossing films by year of release\",\n",
    "    #\"Timeline of the highest-grossing film record\",\n",
    "    #\"Highest-grossing franchises and film series\"\n",
    "]"
   ],
   "id": "ae2499689ec73b99",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create (or connect to) SQLite database",
   "id": "90ec8abaa38cf58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:07:34.317617Z",
     "start_time": "2025-02-28T22:07:34.313769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create or connect to SQLite DB\n",
    "conn = sqlite3.connect(\"films.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the films table if not exists\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS films (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        title TEXT NOT NULL,\n",
    "        release_year INTEGER,\n",
    "        director TEXT,\n",
    "        box_office TEXT,  -- Storing as TEXT for less complexity (symbols, etc.)\n",
    "        country TEXT\n",
    "    )\n",
    "\"\"\")\n",
    "conn.commit()"
   ],
   "id": "db3f337b1b29351b",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  Helper functions to parse each table",
   "id": "50cc1f90845cac5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:07:50.500335Z",
     "start_time": "2025-02-28T22:07:50.494365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_infobox_value(infobox, label):\n",
    "    \"\"\"\n",
    "    Searches the infobox for a <th> whose text contains `label` \n",
    "    (case-insensitive). Returns the text content of the adjacent <td> if found.\n",
    "    \"\"\"\n",
    "    if not infobox or not label:\n",
    "        return None\n",
    "    row = infobox.find(\"th\", string=lambda text: text and label.lower() in text.lower())\n",
    "    if row:\n",
    "        data_cell = row.find_next_sibling(\"td\")\n",
    "        if data_cell:\n",
    "            # Combine all text in that cell\n",
    "            return \" \".join(data_cell.stripped_strings)\n",
    "    return None"
   ],
   "id": "8e7f369982bae26e",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:08:13.853358Z",
     "start_time": "2025-02-28T22:08:13.849633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_directors(director_str):\n",
    "    \"\"\"\n",
    "    Given the 'Directed by' cell's string, parse out multiple directors if present,\n",
    "    returning a comma-separated string.\n",
    "    \"\"\"\n",
    "    if not director_str:\n",
    "        return None\n",
    "    # Split on typical separators: commas, 'and', '&'\n",
    "    # This is simplistic—adjust as needed for edge cases.\n",
    "    possible_separators = r\",| and | & \"\n",
    "    directors_list = re.split(possible_separators, director_str)\n",
    "    # Clean extra spaces\n",
    "    directors_list = [d.strip() for d in directors_list if d.strip()]\n",
    "    # Rejoin in a single comma-separated string\n",
    "    return \", \".join(directors_list)"
   ],
   "id": "10c1717b1c668779",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:08:52.636414Z",
     "start_time": "2025-02-28T22:08:52.629536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_year_from_release_date(date_str):\n",
    "    \"\"\"\n",
    "    Attempt to extract a 4-digit year from a 'Release date' string.\n",
    "    Fallback to None if not found.\n",
    "    \"\"\"\n",
    "    if not date_str:\n",
    "        return None\n",
    "    match = re.search(r\"\\b(19|20)\\d{2}\\b\", date_str)\n",
    "    if match:\n",
    "        return int(match.group(0))\n",
    "    return None"
   ],
   "id": "cf6eb9c9bbf90766",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:09:00.981023Z",
     "start_time": "2025-02-28T22:09:00.978474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_box_office(box_office_str):\n",
    "    \"\"\"\n",
    "    Return the raw string or do some minimal cleanup. \n",
    "    We could remove symbols and parse as float, but some pages might have multiple\n",
    "    numbers or ranges. For simplicity, store as TEXT or do partial numeric cleaning.\n",
    "    \"\"\"\n",
    "    if not box_office_str:\n",
    "        return None\n",
    "    # Example: remove footnote references like [1]\n",
    "    cleaned = re.sub(r\"\\[\\d+\\]\", \"\", box_office_str)\n",
    "    cleaned = cleaned.strip()\n",
    "    return cleaned if cleaned else None"
   ],
   "id": "9a4c9aca27e9bc57",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:09:19.499593Z",
     "start_time": "2025-02-28T22:09:19.494636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_country(country_str):\n",
    "    \"\"\"\n",
    "    Clean up the 'Country' field from the infobox if present.\n",
    "    \"\"\"\n",
    "    if not country_str:\n",
    "        return None\n",
    "    # Remove possible footnote brackets, etc.\n",
    "    cleaned = re.sub(r\"\\[\\d+\\]\", \"\", country_str).strip()\n",
    "    return cleaned"
   ],
   "id": "ddbce277636fab39",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:10:52.913082Z",
     "start_time": "2025-02-28T22:10:52.902171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_film_page(film_url):\n",
    "    \"\"\"\n",
    "    Given a partial or full Wikipedia link to a specific film page:\n",
    "    1. Request the page\n",
    "    2. Parse the infobox\n",
    "    3. Extract director(s), release year, box office, and country\n",
    "    4. Return these as a dict\n",
    "    \"\"\"\n",
    "    # Some links might already contain the full domain, others might be relative\n",
    "    if film_url.startswith(\"/wiki/\"):\n",
    "        film_url = \"https://en.wikipedia.org\" + film_url\n",
    "\n",
    "    # Polite delay to avoid rate-limiting (optional but recommended)\n",
    "    time.sleep(1)\n",
    "\n",
    "    resp = requests.get(film_url)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Warning: Could not fetch {film_url}\")\n",
    "        return {}\n",
    "\n",
    "    film_soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    # Locate the standard film infobox, typically class=\"infobox vevent\"\n",
    "    infobox = film_soup.find(\"table\", class_=\"infobox vevent\")\n",
    "    if not infobox:\n",
    "        # Some pages might not have a standard infobox\n",
    "        return {}\n",
    "\n",
    "    # Extract data from the infobox\n",
    "    raw_director = get_infobox_value(infobox, \"Directed by\")\n",
    "    director = parse_directors(raw_director)\n",
    "\n",
    "    raw_release_date = get_infobox_value(infobox, \"Release date\") or \\\n",
    "                       get_infobox_value(infobox, \"Release dates\") or \\\n",
    "                       get_infobox_value(infobox, \"Released\")\n",
    "\n",
    "    release_year = parse_year_from_release_date(raw_release_date)\n",
    "\n",
    "    raw_box_office = get_infobox_value(infobox, \"Box office\")\n",
    "    box_office = parse_box_office(raw_box_office)\n",
    "\n",
    "    raw_country = get_infobox_value(infobox, \"Country\")\n",
    "    country = parse_country(raw_country)\n",
    "\n",
    "    return {\n",
    "        \"director\": director,\n",
    "        \"release_year\": release_year,\n",
    "        \"box_office\": box_office,\n",
    "        \"country\": country\n",
    "    }"
   ],
   "id": "2059c2c44a0988b3",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SCRAPE THE MAIN PAGE & PARSE TARGET TABLE(S)",
   "id": "1a65789e24a37326"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:11:01.463749Z",
     "start_time": "2025-02-28T22:11:00.472908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = requests.get(WIKI_URL)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Identify the relevant tables by caption\n",
    "tables = []\n",
    "for caption_tag in soup.find_all('caption'):\n",
    "    caption_text = caption_tag.get_text(strip=True)\n",
    "    if any(main_caption in caption_text for main_caption in MAIN_TABLE_CAPTIONS):\n",
    "        candidate_table = caption_tag.find_parent('table')\n",
    "        tables.append(candidate_table)\n",
    "\n",
    "print(f\"Found {len(tables)} relevant table(s) to parse.\")"
   ],
   "id": "be422418485c8072",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 relevant table(s) to parse.\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:14:48.821188Z",
     "start_time": "2025-02-28T22:13:14.076566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For each relevant table, we parse rows\n",
    "for tbl in tables:\n",
    "    rows = tbl.find_all(\"tr\")\n",
    "    # Usually skip the header row\n",
    "    for row in rows[1:]:\n",
    "        cells = row.find_all([\"th\",\"td\"])\n",
    "        if not cells:\n",
    "            continue\n",
    "        \n",
    "        # Attempt to locate the film link in the 'Title' cell\n",
    "        # Some tables have the film title in a <th scope=\"row\">,\n",
    "        # others might be in a <td>. Adjust as needed.\n",
    "\n",
    "        film_link_tag = None\n",
    "        \n",
    "        # A common pattern: the 2nd or 3rd cell might have the film <a> tag\n",
    "        # Or we check for <th scope=\"row\"> with <a> inside\n",
    "        # We'll just search for any <a> inside the row that leads to a wiki film page:\n",
    "        for cell in cells:\n",
    "            link = cell.find(\"a\", href=True)\n",
    "            if link and link['href'].startswith(\"/wiki/\"):\n",
    "                film_link_tag = link\n",
    "                break\n",
    "        \n",
    "        if not film_link_tag:\n",
    "            continue\n",
    "        \n",
    "        film_title = film_link_tag.get_text(strip=True)\n",
    "        film_href = film_link_tag['href']\n",
    "\n",
    "        # Now open that film page to parse the infobox\n",
    "        film_details = scrape_film_page(film_href)\n",
    "        if not film_details:\n",
    "            print(f\"Could not parse infobox for film: {film_title}\")\n",
    "            continue\n",
    "        \n",
    "        director = film_details.get(\"director\")\n",
    "        release_year = film_details.get(\"release_year\")\n",
    "        box_office = film_details.get(\"box_office\")\n",
    "        country = film_details.get(\"country\")\n",
    "\n",
    "        # --------------------------------------------\n",
    "        # 4. INSERT INTO DATABASE\n",
    "        # --------------------------------------------\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO films (title, release_year, director, box_office, country)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "        \"\"\", (film_title, release_year, director, box_office, country))\n",
    "        conn.commit()\n",
    "\n",
    "        print(f\"Inserted: {film_title} (Year={release_year}, Dir={director}, BoxOffice={box_office}, Country={country})\")\n",
    "\n",
    "# Cleanup\n",
    "conn.close()\n",
    "print(\"Done. Database populated with film data.\")"
   ],
   "id": "5995881ee58a74e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted: Avatar (Year=2009, Dir=James Cameron, BoxOffice=$2.923 billion [ 5 ], Country=None)\n",
      "Inserted: Avengers: Endgame (Year=2019, Dir=Anthony Russo Joe Russo, BoxOffice=$2.799 billion [ 4 ], Country=United States)\n",
      "Inserted: Avatar: The Way of Water (Year=2022, Dir=James Cameron, BoxOffice=$2.320 billion [ 4 ] [ 5 ], Country=United States)\n",
      "Inserted: Titanic (Year=1997, Dir=James Cameron, BoxOffice=$2.264 billion [ 7 ], Country=United States)\n",
      "Inserted: Star Wars: The Force Awakens (Year=2015, Dir=J. J. Abrams, BoxOffice=$2.07 billion [ 3 ], Country=United States)\n",
      "Inserted: Avengers: Infinity War (Year=2018, Dir=Anthony Russo Joe Russo, BoxOffice=$2.052 billion [ 4 ], Country=United States)\n",
      "Inserted: Ne Zha 2 (Year=2025, Dir=Jiaozi, BoxOffice=US$1.94 billion [ 2 ] [ 3 ], Country=China)\n",
      "Inserted: Spider-Man: No Way Home (Year=2021, Dir=Jon Watts, BoxOffice=$1.923 billion [ 3 ] [ 4 ], Country=United States)\n",
      "Inserted: Inside Out 2 (Year=2024, Dir=Kelsey Mann, BoxOffice=$1.699 billion [ 3 ] [ 4 ], Country=United States)\n",
      "Inserted: Jurassic World (Year=2015, Dir=Colin Trevorrow, BoxOffice=$1.671 billion [ 4 ], Country=United States)\n",
      "Inserted: The Lion King (Year=2019, Dir=Jon Favreau, BoxOffice=$1.657 billion [ 5 ], Country=United States)\n",
      "Inserted: The Avengers (Year=2012, Dir=Joss Whedon, BoxOffice=$1.521 billion [ 4 ], Country=United States)\n",
      "Inserted: Furious 7 (Year=2015, Dir=James Wan, BoxOffice=$1.515 billion [ 4 ], Country=None)\n",
      "Inserted: Top Gun: Maverick (Year=2022, Dir=Joseph Kosinski, BoxOffice=$1.496 billion [ 4 ] [ 5 ], Country=United States)\n",
      "Inserted: Frozen 2 (Year=2019, Dir=Chris Buck Jennifer Lee, BoxOffice=$1.453 billion, Country=United States)\n",
      "Inserted: Barbie (Year=2023, Dir=Greta Gerwig, BoxOffice=$1.446 billion [ 6 ] [ 7 ], Country=None)\n",
      "Inserted: Avengers: Age of Ultron (Year=2015, Dir=Joss Whedon, BoxOffice=$1.405 billion [ 4 ], Country=United States)\n",
      "Inserted: The Super Mario Bros. Movie (Year=2023, Dir=Aaron Horvath Michael Jelenic, BoxOffice=$1.363 billion [ 3 ] [ 4 ], Country=United States)\n",
      "Inserted: Black Panther (Year=2018, Dir=Ryan Coogler, BoxOffice=$1.35 billion [ 4 ], Country=United States)\n",
      "Inserted: Harry Potter and the Deathly Hallows – Part 2 (Year=2011, Dir=David Yates, BoxOffice=$1.342 billion [ 4 ], Country=None)\n",
      "Inserted: Deadpool & Wolverine (Year=2024, Dir=Shawn Levy, BoxOffice=$1.338 billion [ 3 ] [ 4 ], Country=United States)\n",
      "Inserted: Star Wars: The Last Jedi (Year=2017, Dir=Rian Johnson, BoxOffice=$1.334 billion [ 3 ], Country=United States)\n",
      "Inserted: Jurassic World: Fallen Kingdom (Year=2018, Dir=J. A. Bayona, BoxOffice=$1.31 billion [ 7 ], Country=None)\n",
      "Inserted: Frozen (Year=2013, Dir=Chris Buck Jennifer Lee, BoxOffice=$1.280 billion [ 7 ], Country=United States)\n",
      "Inserted: Beauty and the Beast (Year=2017, Dir=Bill Condon, BoxOffice=$1.266 billion [ 3 ], Country=United States)\n",
      "Inserted: Incredibles 2 (Year=2018, Dir=Brad Bird, BoxOffice=$1.243 billion [ 4 ], Country=United States)\n",
      "Inserted: The Fate of the Furious (Year=2017, Dir=F. Gary Gray, BoxOffice=$1.236 billion [ 5 ], Country=None)\n",
      "Inserted: Iron Man 3 (Year=2013, Dir=Shane Black, BoxOffice=$1.266 billion [ 3 ], Country=United States)\n",
      "Inserted: Minions (Year=2015, Dir=Pierre Coffin Kyle Balda, BoxOffice=$1.159 billion [ 4 ], Country=United States)\n",
      "Inserted: Captain America: Civil War (Year=2016, Dir=Anthony Russo Joe Russo, BoxOffice=$1.155 billion [ 4 ], Country=United States)\n",
      "Inserted: Aquaman (Year=2018, Dir=James Wan, BoxOffice=$1.152 billion [ 7 ], Country=United States)\n",
      "Inserted: The Lord of the Rings: The Return of the King (Year=2003, Dir=Peter Jackson, BoxOffice=$1.151 billion [ 4 ], Country=None)\n",
      "Inserted: Spider-Man: Far From Home (Year=2019, Dir=Jon Watts, BoxOffice=$1.133 billion [ 3 ], Country=United States)\n",
      "Inserted: Captain Marvel (Year=2019, Dir=Anna Boden Ryan Fleck, BoxOffice=$1.131 billion [ 4 ], Country=United States)\n",
      "Inserted: Transformers: Dark of the Moon (Year=2011, Dir=Michael Bay, BoxOffice=$1.124 billion [ 7 ], Country=United States)\n",
      "Inserted: Skyfall (Year=2012, Dir=Sam Mendes, BoxOffice=$1.109 billion [ 5 ], Country=None)\n",
      "Inserted: Transformers: Age of Extinction (Year=2014, Dir=Michael Bay, BoxOffice=$1.104 billion [ 4 ], Country=United States)\n",
      "Inserted: The Dark Knight Rises (Year=2012, Dir=Christopher Nolan, BoxOffice=$1.115 billion [ 4 ], Country=None)\n",
      "Inserted: Joker (Year=2019, Dir=Todd Phillips, BoxOffice=$1.079 billion [ 2 ] [ 3 ], Country=United States)\n",
      "Inserted: Star Wars: The Rise of Skywalker (Year=2019, Dir=J. J. Abrams, BoxOffice=$1.077 billion [ 3 ], Country=United States)\n",
      "Inserted: Toy Story 4 (Year=2019, Dir=Josh Cooley, BoxOffice=$1.074 billion [ 3 ], Country=United States)\n",
      "Inserted: Toy Story 3 (Year=2010, Dir=Lee Unkrich, BoxOffice=$1.067 billion [ 1 ], Country=United States)\n",
      "Inserted: Pirates of the Caribbean: Dead Man's Chest (Year=2006, Dir=Gore Verbinski, BoxOffice=$1.066 billion [ 2 ], Country=United States)\n",
      "Inserted: Rogue One: A Star Wars Story (Year=2016, Dir=Gareth Edwards, BoxOffice=$1.059 billion [ 5 ], Country=United States)\n",
      "Inserted: Moana 2 (Year=2024, Dir=David Derrick Jr. [ 1 ] Jason Hand [ 1 ] Dana Ledoux Miller [ 1 ], BoxOffice=$1.05 billion [ 5 ] [ 6 ], Country=United States)\n",
      "Inserted: Aladdin (Year=2019, Dir=Guy Ritchie, BoxOffice=$1.054 billion [ 6 ], Country=United States)\n",
      "Inserted: Star Wars: Episode I – The Phantom Menace (Year=1999, Dir=George Lucas, BoxOffice=$1.047 billion [ 3 ] [ 4 ], Country=United States)\n",
      "Inserted: Pirates of the Caribbean: On Stranger Tides (Year=2011, Dir=Rob Marshall, BoxOffice=$1.046 billion [ 3 ], Country=United States)\n",
      "Inserted: Jurassic Park (Year=1993, Dir=Steven Spielberg, BoxOffice=$1.058 billion [ 4 ], Country=United States)\n",
      "Inserted: Despicable Me 3 (Year=2017, Dir=Pierre Coffin Kyle Balda, BoxOffice=$1.035 billion [ 5 ], Country=United States)\n",
      "Inserted: Gone with the Wind (Year=1939, Dir=Victor Fleming, BoxOffice=>$390 million, Country=United States)\n",
      "Inserted: Avatar (Year=2009, Dir=James Cameron, BoxOffice=$2.923 billion [ 5 ], Country=None)\n",
      "Inserted: Titanic (Year=1997, Dir=James Cameron, BoxOffice=$2.264 billion [ 7 ], Country=United States)\n",
      "Inserted: Star Wars (Year=1977, Dir=George Lucas, BoxOffice=$775.4 million [ 3 ], Country=United States [ 2 ])\n",
      "Inserted: Avengers: Endgame (Year=2019, Dir=Anthony Russo Joe Russo, BoxOffice=$2.799 billion [ 4 ], Country=United States)\n",
      "Inserted: The Sound of Music (Year=1965, Dir=Robert Wise, BoxOffice=$286.2 million [ 2 ], Country=United States)\n",
      "Inserted: E.T. the Extra-Terrestrial (Year=1982, Dir=Steven Spielberg, BoxOffice=$797.3 million [ 3 ] [ 5 ], Country=United States)\n",
      "Inserted: The Ten Commandments (Year=1956, Dir=Cecil B. DeMille, BoxOffice=$122.7 million [ 4 ] (initial release), Country=United States)\n",
      "Inserted: Doctor Zhivago (Year=1965, Dir=David Lean, BoxOffice=$111.7 million (US/Canada) [ 4 ] 248.2 million tickets (worldwide) [ 5 ], Country=None)\n",
      "Inserted: Star Wars: The Force Awakens (Year=2015, Dir=J. J. Abrams, BoxOffice=$2.07 billion [ 3 ], Country=United States)\n",
      "Done. Database populated with film data.\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create the “Insights” Table",
   "id": "5a7b84c8530edeb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:33:07.867005Z",
     "start_time": "2025-02-28T22:33:07.860443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"films.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Optional: create a table to hold per-film insights\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS film_insights (\n",
    "        insight_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        film_id INTEGER,\n",
    "        insight TEXT,\n",
    "        FOREIGN KEY (film_id) REFERENCES films(id)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ],
   "id": "5f876a6e66e683ee",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LLM Tools :)",
   "id": "30d7fdedd1eb84b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:33:09.383026Z",
     "start_time": "2025-02-28T22:33:09.378741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_cleaning_prompt(film_dict):\n",
    "    \"\"\"\n",
    "    Creates a text prompt that asks the LLM to clean the film data.\n",
    "    Return a string that you'll send to the LLM endpoint.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a data-cleaning assistant. I have the following film entry:\n",
    "    \n",
    "    Title: {film_dict[\"title\"]}\n",
    "    Release Year: {film_dict[\"release_year\"]}\n",
    "    Director(s): {film_dict[\"director\"]}\n",
    "    Box Office: {film_dict[\"box_office\"]}\n",
    "    Country: {film_dict[\"country\"]}\n",
    "    \n",
    "    1. Remove bracketed references like [1], [ 2 ], or [ 3 ] from all fields.\n",
    "    2. Convert Box Office to a consistent numeric format. \n",
    "       - For example, if the value is \"$2.923 billion [ 5 ]\", remove bracket references \n",
    "         and keep convert to numeric (e.g. 2923000000). \n",
    "    3. Standardize the Country field to something like \"United States\" or \"United Kingdom\" if it's partially included.\n",
    "    4. Output your final result in valid JSON with the following keys exactly:\n",
    "       title, release_year, director, box_office, country\n",
    "       \n",
    "    ONLY return the JSON object. Do not include other text.\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ],
   "id": "68ac23653e39ec7f",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:33:10.980347Z",
     "start_time": "2025-02-28T22:33:10.974859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import aiohttp\n",
    "import os\n",
    "\n",
    "LLM_ENDPOINT = os.environ['LLM_ENDPOINT']\n",
    "\n",
    "async def call_llm(prompt, \n",
    "             model=\"Meta-Llama-3.1-70B-Instruct\", \n",
    "             temperature=0.7, \n",
    "             max_tokens=400, \n",
    "             top_p=0.9, \n",
    "             n=1):\n",
    "    \"\"\"\n",
    "    Makes a POST request to your local LLM endpoint with the specified\n",
    "    prompt and parameters. Returns the assistant's message content.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "                \"name\": \"user\"\n",
    "            }\n",
    "        ],\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"top_p\": top_p,\n",
    "        \"n\": n\n",
    "    }\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(LLM_ENDPOINT, json=payload) as response:\n",
    "            if response.status != 200:\n",
    "                raise Exception(f\"Error {response.status} from endpoint: {LLM_ENDPOINT}\")\n",
    "            \n",
    "            result_json = await response.json()\n",
    "            try:\n",
    "                result = result_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "            except Exception:\n",
    "                result = str(result_json)\n",
    "    \n",
    "    return result"
   ],
   "id": "29f591a1d5e9b12",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:37:19.600028Z",
     "start_time": "2025-02-28T22:33:13.994253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "async def clean_and_update_films():\n",
    "    conn = sqlite3.connect(\"films.db\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Step 1: Get all records\n",
    "    cursor.execute(\"SELECT id, title, release_year, director, box_office, country FROM films\")\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # We'll store them in a list of dicts for convenience\n",
    "    film_records = []\n",
    "    for row in rows:\n",
    "        film_records.append({\n",
    "            \"id\": row[0],\n",
    "            \"title\": row[1],\n",
    "            \"release_year\": row[2],\n",
    "            \"director\": row[3],\n",
    "            \"box_office\": row[4],\n",
    "            \"country\": row[5]\n",
    "        })\n",
    "\n",
    "    # Step 2: For each film, build a prompt and call LLM\n",
    "    for film_dict in film_records:\n",
    "        prompt = build_cleaning_prompt(film_dict)\n",
    "\n",
    "        # Call your local LLM endpoint\n",
    "        cleaned_response = await call_llm(\n",
    "            prompt,\n",
    "            model=\"Meta-Llama-3.1-70B-Instruct\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=400,\n",
    "            top_p=0.9,\n",
    "            n=1\n",
    "        )\n",
    "\n",
    "        # Step 3: Parse the JSON response\n",
    "        try:\n",
    "            cleaned_data = json.loads(cleaned_response)\n",
    "            # cleaned_data should contain keys: title, release_year, director, box_office, country\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: Could not parse JSON for film ID {film_dict['id']}\")\n",
    "            continue\n",
    "\n",
    "        # Let's handle cases where the LLM might not supply a field\n",
    "        title = cleaned_data.get(\"title\", film_dict[\"title\"])\n",
    "        release_year = cleaned_data.get(\"release_year\", film_dict[\"release_year\"])\n",
    "        director = cleaned_data.get(\"director\", film_dict[\"director\"])\n",
    "        box_office = cleaned_data.get(\"box_office\", film_dict[\"box_office\"])\n",
    "        country = cleaned_data.get(\"country\", film_dict[\"country\"])\n",
    "\n",
    "        try:\n",
    "            cursor.execute(\"\"\"\n",
    "                UPDATE films\n",
    "                SET title = ?, \n",
    "                    release_year = ?, \n",
    "                    director = ?, \n",
    "                    box_office = ?, \n",
    "                    country = ?\n",
    "                WHERE id = ?\n",
    "            \"\"\", (title, release_year, director, box_office, country, film_dict[\"id\"]))\n",
    "            conn.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating film ID {film_dict['id']}: {e}\")\n",
    "        \n",
    "        insight_prompt = f\"\"\"\n",
    "Give me a single short sentence insight about the film:\n",
    "Title: {title}\n",
    "Release Year: {release_year}\n",
    "Director: {director}\n",
    "Box Office: {box_office}\n",
    "Country: {country}\n",
    "\n",
    "Only return a single short sentence as plain text.\n",
    "        \"\"\"\n",
    "        insight_text = await call_llm(\n",
    "            insight_prompt,\n",
    "            model=\"Meta-Llama-3.1-70B-Instruct\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=60,\n",
    "            top_p=0.9,\n",
    "            n=1\n",
    "        )\n",
    "\n",
    "        # Insert insight into film_insights table\n",
    "        try:\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO film_insights (film_id, insight)\n",
    "                VALUES (?, ?)\n",
    "            \"\"\", (film_dict[\"id\"], insight_text.strip()))\n",
    "            conn.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting insight for film ID {film_dict['id']}: {e}\")\n",
    "\n",
    "        print(f\"Cleaned & updated film ID {film_dict['id']}: {title}\")\n",
    "        \n",
    "    conn.close()\n",
    "    print(\"All films processed and cleaned.\")\n",
    "\n",
    "\n",
    "# Finally, run the coroutine in an event loop (if you're in a normal .py script)\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(clean_and_update_films())"
   ],
   "id": "e64a123e81cc51d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned & updated film ID 1: Avatar\n",
      "Cleaned & updated film ID 2: Avengers: Endgame\n",
      "Cleaned & updated film ID 3: Avatar: The Way of Water\n",
      "Cleaned & updated film ID 4: Titanic\n",
      "Cleaned & updated film ID 5: Star Wars: The Force Awakens\n",
      "Cleaned & updated film ID 6: Avengers: Infinity War\n",
      "Cleaned & updated film ID 7: Ne Zha 2\n",
      "Cleaned & updated film ID 8: Spider-Man: No Way Home\n",
      "Cleaned & updated film ID 9: Inside Out 2\n",
      "Cleaned & updated film ID 10: Jurassic World\n",
      "Cleaned & updated film ID 11: The Lion King\n",
      "Cleaned & updated film ID 12: The Avengers\n",
      "Cleaned & updated film ID 13: Furious 7\n",
      "Cleaned & updated film ID 14: Top Gun: Maverick\n",
      "Cleaned & updated film ID 15: Frozen 2\n",
      "Cleaned & updated film ID 16: Barbie\n",
      "Cleaned & updated film ID 17: Avengers: Age of Ultron\n",
      "Cleaned & updated film ID 18: The Super Mario Bros. Movie\n",
      "Cleaned & updated film ID 19: Black Panther\n",
      "Cleaned & updated film ID 20: Harry Potter and the Deathly Hallows – Part 2\n",
      "Cleaned & updated film ID 21: Deadpool & Wolverine\n",
      "Cleaned & updated film ID 22: Star Wars: The Last Jedi\n",
      "Cleaned & updated film ID 23: Jurassic World: Fallen Kingdom\n",
      "Cleaned & updated film ID 24: Frozen\n",
      "Cleaned & updated film ID 25: Beauty and the Beast\n",
      "Cleaned & updated film ID 26: Incredibles 2\n",
      "Cleaned & updated film ID 27: The Fate of the Furious\n",
      "Cleaned & updated film ID 28: Iron Man 3\n",
      "Cleaned & updated film ID 29: Minions\n",
      "Cleaned & updated film ID 30: Captain America: Civil War\n",
      "Cleaned & updated film ID 31: Aquaman\n",
      "Cleaned & updated film ID 32: The Lord of the Rings: The Return of the King\n",
      "Cleaned & updated film ID 33: Spider-Man: Far From Home\n",
      "Cleaned & updated film ID 34: Captain Marvel\n",
      "Cleaned & updated film ID 35: Transformers: Dark of the Moon\n",
      "Cleaned & updated film ID 36: Skyfall\n",
      "Cleaned & updated film ID 37: Transformers: Age of Extinction\n",
      "Cleaned & updated film ID 38: The Dark Knight Rises\n",
      "Cleaned & updated film ID 39: Joker\n",
      "Cleaned & updated film ID 40: Star Wars: The Rise of Skywalker\n",
      "Cleaned & updated film ID 41: Toy Story 4\n",
      "Cleaned & updated film ID 42: Toy Story 3\n",
      "Cleaned & updated film ID 43: Pirates of the Caribbean: Dead Man's Chest\n",
      "Cleaned & updated film ID 44: Rogue One: A Star Wars Story\n",
      "Cleaned & updated film ID 45: Moana 2\n",
      "Cleaned & updated film ID 46: Aladdin\n",
      "Cleaned & updated film ID 47: Star Wars: Episode I – The Phantom Menace\n",
      "Cleaned & updated film ID 48: Pirates of the Caribbean: On Stranger Tides\n",
      "Cleaned & updated film ID 49: Jurassic Park\n",
      "Cleaned & updated film ID 50: Despicable Me 3\n",
      "Cleaned & updated film ID 51: Gone with the Wind\n",
      "Cleaned & updated film ID 54: Star Wars\n",
      "Cleaned & updated film ID 56: The Sound of Music\n",
      "Cleaned & updated film ID 57: E.T. the Extra-Terrestrial\n",
      "Cleaned & updated film ID 58: The Ten Commandments\n",
      "Cleaned & updated film ID 59: Doctor Zhivago\n",
      "All films processed and cleaned.\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Removing Duplicate Rows in films by title",
   "id": "b6e462d7e0ec227f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:37:19.621297Z",
     "start_time": "2025-02-28T22:37:19.615850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"films.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Step 1: Delete duplicates in 'films', keeping only the row with the MIN(id) for each title\n",
    "cursor.execute(\"\"\"\n",
    "    DELETE FROM films\n",
    "    WHERE id NOT IN (\n",
    "        SELECT MIN(id)\n",
    "        FROM films\n",
    "        GROUP BY title\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ],
   "id": "75dfc79dc739977b",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  Keeping Only One Entry per film_id in film_insights ",
   "id": "5321d3f48ecad50a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:37:19.883461Z",
     "start_time": "2025-02-28T22:37:19.880869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"films.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Step 2: Delete duplicates in 'film_insights', keeping only the row with the MIN(insight_id) for each film_id\n",
    "cursor.execute(\"\"\"\n",
    "    DELETE FROM film_insights\n",
    "    WHERE insight_id NOT IN (\n",
    "        SELECT MIN(insight_id)\n",
    "        FROM film_insights\n",
    "        GROUP BY film_id\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ],
   "id": "fd3c0bfb43cf7a0a",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Conver to JSON",
   "id": "c02de313b9462d1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T11:57:54.750805Z",
     "start_time": "2025-03-01T11:57:54.733114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import json\n",
    "\n",
    "def export_films_to_json(db_path=\"films.db\", output_file=\"films.json\"):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Optionally join with film_insights table to get short sentences\n",
    "    # If each film has exactly one insight, you can do a LEFT JOIN:\n",
    "    query = \"\"\"\n",
    "    SELECT f.id, \n",
    "           f.title, \n",
    "           f.release_year, \n",
    "           f.director, \n",
    "           f.box_office, \n",
    "           f.country,\n",
    "           i.insight\n",
    "      FROM films f\n",
    "      LEFT JOIN film_insights i ON f.id = i.film_id\n",
    "    ORDER BY f.id\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    # Build a list of dictionaries\n",
    "    # If a film has multiple insights, you'd see duplicates or handle differently\n",
    "    films_data = []\n",
    "    for row in rows:\n",
    "        film_id = row[0]\n",
    "        title = row[1] or \"\"\n",
    "        release_year = row[2]\n",
    "        director = row[3] or \"\"\n",
    "        box_office = row[4]\n",
    "        country = row[5] or \"\"\n",
    "        insight = row[6] or \"\"\n",
    "        \n",
    "        # Convert box_office to a float if it's stored as text, or keep as float if already numeric\n",
    "        try:\n",
    "            box_office_val = float(box_office)\n",
    "        except:\n",
    "            # Fall back to None or 0 if parsing fails\n",
    "            box_office_val = 0\n",
    "        \n",
    "        film_dict = {\n",
    "            \"id\": film_id,\n",
    "            \"title\": title,\n",
    "            \"release_year\": release_year,\n",
    "            \"director\": director,\n",
    "            \"box_office\": box_office_val,\n",
    "            \"country\": country,\n",
    "            \"insight\": insight\n",
    "        }\n",
    "        \n",
    "        films_data.append(film_dict)\n",
    "    \n",
    "    # Close DB connection\n",
    "    conn.close()\n",
    "    \n",
    "    # Write to JSON file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(films_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Exported {len(films_data)} records to {output_file}\")\n",
    "\n",
    "# Usage:\n",
    "if __name__ == \"__main__\":\n",
    "    export_films_to_json(db_path=\"films.db\", output_file=\"films.json\")\n"
   ],
   "id": "8c9a07676b50e151",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 56 records to films.json\n"
     ]
    }
   ],
   "execution_count": 117
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
